{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c15345c2",
   "metadata": {},
   "source": [
    "This is my Functions for the Heatwave, we start with the final function first and work our way backwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ff21f76",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (Temp/ipykernel_32352/2773259814.py, line 88)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\jarra\\AppData\\Local\\Temp/ipykernel_32352/2773259814.py\"\u001b[1;36m, line \u001b[1;32m88\u001b[0m\n\u001b[1;33m    CDP_Time_In_Focus[1],'\u001b[0m\n\u001b[1;37m                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "#%% THE HEATWAVE FUNCTION\n",
    "def Heatwave_Function_Perth_Specific(Dataset,\n",
    "                            date_name,\n",
    "                            Time_In_Focus, \n",
    "                            CDP_Time_In_Focus,\n",
    "                            Temperature_Record_Title,\n",
    "                            percentile,\n",
    "                            window,\n",
    "                            Dates):\n",
    "    '''\n",
    "    This is the heatwave function that is specific to Perth, it will find the 3 days and 2 nights that is required for a\n",
    "    heatwave to begin in Australia and in this research for Perth, and like Nairn et al. has done, made a requirement, that \n",
    "    creates a heatwave that are long periods of abnormally hot temperatures.\n",
    "    \n",
    "    Dataset: 'csv file'\n",
    "        Make sure the index starts off with dates on the right and index going from [0:x]\n",
    "        Max, Min must be part of the record\n",
    "        \n",
    "        \n",
    "    date_name: 'date' csv file.\n",
    "        Date Name so we can split it into day month and year, important for the CDP function to work.\n",
    "    \n",
    "    Time_In_Focus: [Start,End]\n",
    "        Years to be excluded from the data-1910 and 2021 as these are incomplete, but you can add any period you want\n",
    "        as long as you have filled that gaps with NaNs\n",
    "        \n",
    "    CDP_Time_In_Focus: [Start,End]\n",
    "        The reference period for how heatwaves are observed. For example a Heatwave in the futur\n",
    "        \n",
    "    Temperature_Record_Title: ['Max','Min'] or any variation of your maximum or minimum column titles\n",
    "        Name of COlumn that is to be used to extract the temperatures defined by Is_Max_T, this will be required\n",
    "        \n",
    "    percentile: 0 -> 100\n",
    "        The higher the value, the less likely it is for a value that may occur today to be above that percentile value.\n",
    "        90% percentile is the lower value of the values that are within the highest 10% of all values.\n",
    "        \n",
    "    window: 0 -> x days \n",
    "        Used for the CDP, which is the window that is incorporated each day that will be used with the percentile, the longer\n",
    "        the window is the less likely the seasonal variations will affect the temperature changes therefore finidng\n",
    "        the right window is ideal. Best one we have would be between 5-9 days. So 5 to 9 days either side of the day in\n",
    "        focus when using a percentile over the stated time in focus reference period.\n",
    "        \n",
    "    Dates: csv file\n",
    "        Used in the CDP file\n",
    "    '''\n",
    "    #Import Packages\n",
    "    import pandas as pd\n",
    "    \n",
    "    #Clean up data and make sure the format is correct\n",
    "    # Apply datetime to the dataset    \n",
    "    Dataset[date_name] = pd.to_datetime(Dataset[date_name],format=\"%d/%m/%Y\")\n",
    "    \n",
    "    #Had to use 2 versions for the CDP and for the rest of the functions\n",
    "    Data_not_expand = Dataset\n",
    "    Dataset = Date_Splitter(Dataset, date_name)\n",
    "    \n",
    "    '''Max Temp or Min Temp\n",
    "    May not need this, the only reason for this is to find nightime heatwaves\n",
    "    ''' \n",
    "    Is_Max_T = [True,False]\n",
    "    \n",
    "    \n",
    "\n",
    "    '''Start and end Years for the values to use\n",
    "    Start Year will be Nov - 1911 to Mar - 1942\n",
    "    I will classify a year heatwave as the 1911 season as Nov-1911 to Mar-1912\n",
    "\n",
    "    Years to be excluded from the data:\n",
    "    1910 and 2021 as these are incomplete\n",
    "\n",
    "    In the 1880-1900\n",
    "    This will be a different\n",
    "    '''\n",
    "\n",
    "    '''For the Excess Heat Significant Need to Use the CDP function defined beforehand'''\n",
    "    CDP_Max = Calendar_Day_Percentile(Dataset,\n",
    "                                      percentile,\n",
    "                                      window,Dates,\n",
    "                                      Temperature_Record_Title[0],\n",
    "                                      CDP_Time_In_Focus[0],\n",
    "                                      CDP_Time_In_Focus[1],\n",
    "                                      'Temp Max')\n",
    "    CDP_Min = Calendar_Day_Percentile(Dataset,\n",
    "                                      percentile,\n",
    "                                      window,Dates,\n",
    "                                      Temperature_Record_Title[1],\n",
    "                                      CDP_Time_In_Focus[0],\n",
    "                                      CDP_Time_In_Focus[1],'\n",
    "                                      Temp Min')\n",
    "                                                                 \n",
    "    CDP = pd.concat([CDP_Max[date_name],CDP_Max['Temp Max'],CDP_Min['Temp Min']],axis=1) #Change the name\n",
    "\n",
    "\n",
    "\n",
    "    '''Now to put all the heatwave values together to get the 3 Max 2 Min heatwave definition'''\n",
    "    Heatwave_Max, EHF_Max = Perth_Heatwaves_Max(       Data_not_expand,\n",
    "                                                       date_name,Time_In_Focus[0] ,\n",
    "                                                       Time_In_Focus[1] ,\n",
    "                                                       Temperature_Record_Title[0],\n",
    "                                                       CDP_Max,\n",
    "                                                       'Temp Max')\n",
    "    \n",
    "                                      \n",
    "                                      \n",
    "    #Dont think we need this minimum, you will see why all we need is the EHF_Min\n",
    "    EHF_Min = Perth_Min_EHF(Data_not_expand,\n",
    "                            date_name,\n",
    "                            Time_In_Focus[0] ,\n",
    "                            Time_In_Focus[1] ,\n",
    "                            Temperature_Record_Title[1],\n",
    "                            CDP_Min,\n",
    "                            'Temp Min')\n",
    "\n",
    "    #Now apply the 3 day 2 night definition and there is a break already indrudcied\n",
    "    Heatwave_Full_Dataset=  Proper_Heatwaves_Perth_v2(Dataset,  Heatwave_Max,  EHF_Min,  date_name)\n",
    "    return(Heatwave_Full_Dataset,EHF_Max,EHF_Min, CDP)\n",
    "\n",
    "    #So 2 days only are occurring and I believe it is to do with the break \n",
    "    #in the heatwave function, it is only occruing to the onset so i \n",
    "    #believe there is some way i need to mainuplate the break function \n",
    "    #value so it pulls it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13eadd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TnX_Rolling(Before_After_Calendar_Day,Dataset,Percentile_Value):\n",
    "    '''\n",
    "    Before_After_Calendar_Day:\n",
    "    \n",
    "    Dataset:\n",
    "    \n",
    "    Percentile_Value:\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    percent_to_quant = Percentile_Value/100\n",
    "    import numpy as np, warnings\n",
    "    \n",
    "\n",
    "    #Generate empty vector to place the final data in\n",
    "    YearTempData = []\n",
    "    warnings.filterwarnings('ignore')\n",
    "    #Number of days that will contribute to the PARTICULAR calendar day in mind.\n",
    "    D_F_B = Before_After_Calendar_Day\n",
    "    \n",
    "    #for loop for the year long record extracting each calendar day and its surroundings\n",
    "    for central_day in range(366):\n",
    "        \n",
    "        #Now we make the for loop with the central day and the days around it to append to the central da\n",
    "        for around_days in range(0,D_F_B+1):\n",
    "            #First make the 0 if statement\n",
    "            if (around_days == 0):\n",
    "              Temp = Dataset[central_day];\n",
    "              Temp_Storage =  Dataset[central_day]\n",
    "            else:\n",
    "                #Now to create the check so if its at day 366 and the next day should be day 1 and vice versa when going backwards.\n",
    "                \n",
    "                #if statement for if the around_days goes below the lower bound.\n",
    "                if ((central_day - around_days) < 0):\n",
    "                    day_large =  366 - around_days;\n",
    "                    TempU= Dataset[day_large];\n",
    "                    Temp_Storage = Temp_Storage.append(TempU)\n",
    "                    TempL=Dataset[central_day + around_days];\n",
    "                    Temp_Storage = Temp_Storage.append(TempL)\n",
    "                    \n",
    "                #if statement for if the around_days goes above the upper bound.\n",
    "                elif (central_day + around_days) > 365:\n",
    "                    day_small = -1 + around_days;\n",
    "                    TempL=Dataset[day_small];\n",
    "                    Temp_Storage = Temp_Storage.append(TempL)\n",
    "                    TempU=Dataset[central_day - around_days];\n",
    "                    Temp_Storage = Temp_Storage.append(TempU)\n",
    "                #if statement for if the around_days is between the bounds. \n",
    "                else:\n",
    "                    Temp=Dataset[central_day - around_days];\n",
    "                    Temp_Storage = Temp_Storage.append(Temp)\n",
    "                    Temp=Dataset[central_day + around_days];\n",
    "                    Temp_Storage = Temp_Storage.append(Temp)\n",
    "        #Append the data for that calendar and move to the next calendar day.  \n",
    "        YearTempData.append(Temp_Storage)\n",
    "        \n",
    "        \n",
    "        #Percentile based information\n",
    "    \n",
    "    TnX = []\n",
    "    #Create a for loop that uses the YearTempData and find the percentile for that calendar based value.\n",
    "    for i in range(366):\n",
    "        Tn = YearTempData[i].quantile(q=percent_to_quant) #Have a llok properly and code it myslef and pull out ranks and find 90th percetile\n",
    "        TnX = np.append(TnX,Tn)\n",
    "    \n",
    "    return(TnX) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "775859f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "def Calendar_Day_Percentile(Data,percentile,window,Dates,Column_Name,start_year,end_year,temp):\n",
    "    import numpy as np, warnings, pandas as pd\n",
    "    Data = Data[Data['year'] <= end_year]\n",
    "    Data = Data[Data['year'] >= start_year-1]\n",
    "    group_days = Data.groupby(['month','day'])\n",
    "    Daily_Data= []\n",
    "    for groups,days in group_days:\n",
    "        #Extract the specified day bin\n",
    "        Dailypre = group_days.get_group(groups).reset_index()\n",
    "        #Get the maximum values for the entire record for that calendar day\n",
    "        Values= Dailypre[Column_Name]\n",
    "        #Make it a dataframe so it is appendable\n",
    "        Values = Values.to_frame()\n",
    "        #Append that bin to that day so there will be 366 bins with  x years data for that day\n",
    "        Daily_Data.append(Values[Column_Name])\n",
    "            \n",
    "    #Now use CDP 15 day  for the max\n",
    "    CalendarDay = TnX_Rolling(window, Daily_Data, percentile)\n",
    "    CDP = pd.DataFrame(CalendarDay, columns = [temp])\n",
    "    CDP = pd.concat([Dates,CDP],axis=1)\n",
    "    CDP['date'] = pd.to_datetime(CDP['date'],format=\"%d/%m/%Y\")\n",
    "    CDP['year']=CDP['date'].dt.year\n",
    "    CDP['month']=CDP['date'].dt.month\n",
    "    CDP['day']=CDP['date'].dt.day\n",
    "        \n",
    "    return(CDP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24cf1547",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "def Perth_Heatwaves_Max(Data,date_title,Start_Year ,End_Year ,Column_Name,CDP,CDPColumn_Name):\n",
    "    '''    \n",
    "    Data: Dataframe\n",
    "    Dataset we will be using.\n",
    "    \n",
    "    date_title: string\n",
    "    the title of the date column.\n",
    "    \n",
    "    Start_Year: integer\n",
    "    \n",
    "    End_Year: integer\n",
    "    \n",
    "    Both start and end_Year will be within the bounds of the first full year and last full year.\n",
    "    \n",
    "    Example will be Start Year will be Nov - 1911 to Mar - 1942\n",
    "    I will classify a year heatwave as the 1911 season as Nov-1911 to Mar-1912\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    Column_Name = string\n",
    "    Name of COlumn that is to be used to extract the temperatures defined by Is_Max_T\n",
    "\n",
    "    \n",
    "    CDP: dataframe\n",
    "    For the Excess Heat Significant Need to Use the CDP function defined beforehand\n",
    "    CDPColumn_Name = string\n",
    "    Column of the CDP temperature used \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    This is to determine the initiation of the heatwave for the Max and Min temperatures.\n",
    "\n",
    "    The basic theory is that the beginning of a heatwave for Australia and Perth should be:\n",
    "        3 days Max Temp of above average temps\n",
    "        2 days Min Temp of above average temps\n",
    "    '''\n",
    "    Q_Threshold = 3\n",
    "\n",
    "\n",
    "    '''\n",
    "    Now with the Dataset we can define the 33 days. To make it easier get the previous 33 days before Nov for the start period.\n",
    "    '''\n",
    "    Data = Data.set_index([date_title])\n",
    "    CDP =  CDP.set_index([date_title])\n",
    "    Day_S = 29\n",
    "    Month_S = 9\n",
    "    Year_S = Start_Year\n",
    "\n",
    "    Day_E = 30\n",
    "    Month_E = 4\n",
    "    Year_E = End_Year+1\n",
    "\n",
    "    Data_Range = Data.loc['{}-{}-{}'.format(Year_S,Month_S,Day_S):'{}-{}-{}'.format(Year_E,Month_E,Day_E)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    '''\n",
    "    Now developing the first part of the function which will be its own function, the Excess Heat Factor.\n",
    "\n",
    "    Ive realeased that I can save tiem and remove the EHI positive and EHFp as the EHIacc, EHIsig are only needed in the rest of the function.\n",
    "    I will have EHF avalaible to be used though.\n",
    "\n",
    "    In order for this to work properly we will have to reset index.\n",
    "    '''\n",
    "    Data_Range = Data_Range.reset_index()\n",
    "    '''This is an index range of 0 to length-1'''\n",
    "\n",
    "    ''' This is the Excess Heat Factor Function, developed by Nairn 2009'''\n",
    "    #Heatwaves events using a lag for heat-related health issues.\n",
    "    #EHF = Excess_Heat_Factor_Function(Data_Range,date_title,Column_Name,CDP,CDPColumn_Name)\n",
    "    #Heatwave events full\n",
    "    EHF = Excess_Heat_Factor_Function_v3(Data_Range,date_title,Column_Name,CDP,CDPColumn_Name)\n",
    "\n",
    "    '''These are the hot periods which is not heatwaves but these are the hotter then average periods developed\n",
    "    by the EHF.\n",
    "    '''\n",
    "    Hot_Periods = hot_period_Classification(EHF,Q_Threshold)\n",
    "\n",
    "    '''To concude my wonderful function for heatwaves in perth this is the final output'''\n",
    "    Heatwaves_Max= Heatwaves_Defined(Hot_Periods,date_title)\n",
    "\n",
    "\n",
    "    return(Heatwaves_Max, EHF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74d35050",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Excess_Heat_Factor_Function_v3(Data,date_title,Column_Name,CDP,CDPColumn_Name):\n",
    "    '''\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Data : True or False\n",
    "        It is already caterogised as False therefore to use it for Maximum Temperatures need to say True.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    The threshold in order to be a heatwave. Of heatwave events, not heatwaves that cause humans discomfort\n",
    "\n",
    "    '''\n",
    "    import numpy as np ,pandas as pd\n",
    "    #I want to see whether this has better accuracy for heatwaves???\n",
    "    \n",
    "    \n",
    "    Date_Value = [] #To match the EHF values to the date.\n",
    "    EHF = [] #Excess Heat Factor\n",
    "    EHIacc = [] #Excess Heat Index Acclimatised (Previous 32 days)\n",
    "    EHIsig = [] #Excess Heat Index Singificant (CDP value)\n",
    "\n",
    "    for dt in np.arange(Data.index[0]+33,len(Data)):\n",
    "        #----- Date Index -----#\n",
    "        Dates = Data[date_title].loc[dt]\n",
    "        #print(Dates)\n",
    "        #----- 3 day Mean -----#\n",
    "        mean_3_day = Data[Column_Name].loc[dt-2:dt].mean()\n",
    "        #print(mean_3_day)\n",
    "        # ----- 3 to 32 day mean ----#\n",
    "        mean_1_tp_30_day = Data[Column_Name].loc[dt-32:dt-3].mean()\n",
    "        #print(mean_3_tp_32_day)\n",
    "        #----EHI(accl.)----#\n",
    "        EHIacclim_single =  mean_3_day - mean_1_tp_30_day\n",
    "        #print(EHIacclim_single)\n",
    "        #----Tn CDP function----#\n",
    "        '''For that indivudal date we use the Date_Splitter to get the day and month out so we can find the CDP value'''\n",
    "        CDP_day = CDP[CDPColumn_Name].loc['2020-{}-{}'.format(Data['month'].loc[dt],Data['day'].loc[dt])]\n",
    "        \n",
    "        #------ EHI(sig.) ------#\n",
    "        EHIsig_single =  Data[Column_Name].loc[dt] -  CDP_day\n",
    "        \n",
    "        #----- EHF-----#\n",
    "        '''Now using the combination of the two EHI sig and acc we can now produce the EHF, sp this means if negative, it\n",
    "        is alwasy negative when multiplying them together'''\n",
    "        if ((EHIacclim_single <0) and (EHIsig_single <0)):\n",
    "            EHF_single =  -1*EHIacclim_single* EHIsig_single #degC^2\n",
    "        else:\n",
    "            EHF_single =  EHIacclim_single* EHIsig_single #degC^2\n",
    "        \n",
    "        \n",
    "        '''Now with all the necassary information needed we can append it all together'''\n",
    "        Date_Value.append(Dates)\n",
    "        EHIacc.append(EHIacclim_single)\n",
    "        EHIsig.append(EHIsig_single)\n",
    "        EHF.append(EHF_single)\n",
    "        #print(EHIacc)\n",
    "    '''Putting all the vectors together'''\n",
    "    EHF = pd.DataFrame(EHF,columns=['Excess Heat Factor'])\n",
    "    EHIacc = pd.DataFrame(EHIacc,columns=['Excess Heat Index Acclimatised'])\n",
    "    EHIsig = pd.DataFrame(EHIsig,columns=['Excess Heat Index Significant'])\n",
    "    Date_Value = pd.DataFrame(Date_Value,columns=[date_title])\n",
    "   \n",
    "\n",
    "    EHFvect = pd.concat([Date_Value, EHIacc, EHIsig, EHF],axis=1)\n",
    "    Excess_Heat_Factor_Matrix = pd.merge(Data,EHFvect,how='right',on = [date_title])\n",
    "    \n",
    "    return(Excess_Heat_Factor_Matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6053a2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "def hot_period_Classification(EHF,Q):\n",
    "    '''\n",
    "    \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    EHF : Dataframe\n",
    "        From another function in defining heatwaves in the extended Summer period.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    The hot periods throughout the year, these include heatwaves and warmwaves\n",
    "    throughout the defined period.\n",
    "\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    import numpy as np ,pandas as pd\n",
    "    '''Lets create a few lists essential for the hot periods and count functions'''\n",
    "    list_hot_period = []\n",
    "    heat_days = 0\n",
    "    count  = 0\n",
    "    break_days = 2 #Since the first day cannot be a heatwave if it was 0 it would automatically create a heatwave\n",
    "    \n",
    "    '''The first for loop is essentially checking to see if the day in focus is classified as a hot period day, and the \n",
    "    onset is for 3 or more days. I am not sure if I can cut this down'''\n",
    "    #This is the full period with the assciated EHI and EHF values\n",
    "    for dt in np.arange(EHF.index[0],len(EHF)):\n",
    "        '''\n",
    "        Now define the algorithm which for anything greater then 2 or 3 days is classified as a hot period.\n",
    "        See thesis into how it works.\n",
    "        '''\n",
    "        '''Check If heat_days count is already => 3'''\n",
    "        if (heat_days >= Q):\n",
    "            '''Since this if statement is true then we develop the contiuation of the hot period event'''\n",
    "            if(EHF['Excess Heat Index Significant'][dt] > 0):\n",
    "                #As long as EHIsig > 0 then there is a prolonged heatwave\n",
    "                heat_days = heat_days + 1\n",
    "                break_days = 0 \n",
    "            #Define the ending of the hot period, without the break at the moment\n",
    "            else:\n",
    "                break_days = break_days + 1\n",
    "                #Now this is the interesting point, we can implement a break in the system\n",
    "                if(break_days > 1):\n",
    "                        #This will stop the hot period event and add an id on the event with a count function.\n",
    "                        count = count+1\n",
    "                        hot_period = EHF.loc[dt-heat_days:dt-2]\n",
    "                        hot_period['id'] = [count] * len(hot_period)\n",
    "                        list_hot_period.append(hot_period)\n",
    "                        heat_days=0\n",
    "                else:\n",
    "                        #This will continue the hot period until break_days > 1\n",
    "                        heat_days = heat_days + 1\n",
    "                        \n",
    "                \n",
    "            \n",
    "        #Define everything for the initiation of the hot period\n",
    "        \n",
    "        else:\n",
    "            '''\n",
    "            Now this is the criteria for the start of a hot period event, 3 max or 2 min.\n",
    "            '''\n",
    "            break_days = 0\n",
    "            #Define everything for the initiation of the hot period\n",
    "            if((EHF['Excess Heat Index Acclimatised'][dt]> 0) and (EHF['Excess Heat Index Significant'][dt] > 0)):\n",
    "                heat_days = heat_days + 1\n",
    "            else:\n",
    "                heat_days  = 0\n",
    "\n",
    "    hot_period_df = pd.concat(list_hot_period,axis=0)\n",
    "    return(hot_period_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c558747",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "def Heatwaves_Defined(Hot_Periods,date_title):\n",
    "    import numpy as np ,pandas as pd\n",
    "    \n",
    "    #Get dates into days months and years\n",
    "    Hot_Per = Date_Splitter(Hot_Periods, date_title)\n",
    "\n",
    "    '''This finds the heatwaves that reside in the extended summer period defined by Novmeber to March'''\n",
    "    ext_sum_heatwave = (Hot_Periods.loc[Hot_Periods['month']>=11])\n",
    "    ext_sum_heatwave2 =  Hot_Periods.loc[Hot_Periods['month']<=3]\n",
    "    Extended_Summer_Season = pd.concat([ext_sum_heatwave,ext_sum_heatwave2]).sort_values(by=[date_title], ascending=True)\n",
    "\n",
    "    '''Generate a list of ids that will be used and checked to see if they are on the bounds of Nov and March\n",
    "    as these are o as the bounds cut off heatwaves that begin or end of Nov and Mar respectively'''\n",
    "    id_Max = Extended_Summer_Season['id'] \n",
    "    ids = id_Max.drop_duplicates( keep='first', inplace=False)\n",
    "\n",
    "\n",
    "    '''The checker for the left and right bounds'''\n",
    "    for i in ids:\n",
    "        #Checks November-1\n",
    "        CheckL = Extended_Summer_Season[Extended_Summer_Season['id']==i]\n",
    "        LeftCheck = CheckL[CheckL['day']==1]\n",
    "        LeftCheck = LeftCheck[LeftCheck['month']==11]\n",
    "        #Checks March-31\n",
    "        CheckR = Extended_Summer_Season[Extended_Summer_Season['id']==i]\n",
    "        RightCheck = CheckR[CheckR['day']==31]\n",
    "        RightCheck = RightCheck[RightCheck['month']==3]\n",
    "        #If there is a value on the ends here it add it to the heatwave list\n",
    "        if (len(LeftCheck) == 1):\n",
    "            Extended_Summer_Season = pd.concat([Extended_Summer_Season,Hot_Per[Hot_Per['id']==i]]).sort_values(by=[date_title], ascending=True)   \n",
    "            #print(1)\n",
    "        elif (len(RightCheck) == 1):\n",
    "            Extended_Summer_Season = pd.concat([Extended_Summer_Season,Hot_Per[Hot_Per['id']==i]]).sort_values(by=[date_title], ascending=True)\n",
    "    # removes the duplicates if there were heatwaves on any of the bounds\n",
    "    Extended_Summer_Season= Extended_Summer_Season.drop_duplicates(subset = [date_title],keep='first')\n",
    "    Heatwaves = Extended_Summer_Season.drop(['day','month','year'],axis=1)\n",
    "    return(Heatwaves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eee9251d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "def Perth_Min_EHF(Data,date_title,Start_Year ,End_Year ,Column_Name,CDP,CDPColumn_Name):\n",
    "    '''    \n",
    "    Data: Dataframe\n",
    "    Dataset we will be using.\n",
    "    \n",
    "    date_title: string\n",
    "    the title of the date column.\n",
    "    \n",
    "    Start_Year: integer\n",
    "    \n",
    "    End_Year: integer\n",
    "    \n",
    "    Both start and end_Year will be within the bounds of the first full year and last full year.\n",
    "    \n",
    "    Example will be Start Year will be Nov - 1911 to Mar - 1942\n",
    "    I will classify a year heatwave as the 1911 season as Nov-1911 to Mar-1912\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    Column_Name = string\n",
    "    Name of COlumn that is to be used to extract the temperatures defined by Is_Max_T\n",
    "\n",
    "    \n",
    "    CDP: dataframe\n",
    "    For the Excess Heat Significant Need to Use the CDP function defined beforehand\n",
    "    CDPColumn_Name = string\n",
    "    Column of the CDP temperature used \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    '''\n",
    "    Now with the Dataset we can define the 33 days. To make it easier get the previous 33 days before Nov for the start period.\n",
    "    '''\n",
    "    Data = Data.set_index([date_title])\n",
    "    CDP =  CDP.set_index([date_title])\n",
    "    Day_S = 29\n",
    "    Month_S = 9\n",
    "    Year_S = Start_Year\n",
    "\n",
    "    Day_E = 30\n",
    "    Month_E = 4\n",
    "    Year_E = End_Year+1\n",
    "\n",
    "    Data_Range = Data.loc['{}-{}-{}'.format(Year_S,Month_S,Day_S):'{}-{}-{}'.format(Year_E,Month_E,Day_E)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    '''\n",
    "    Now developing the first part of the function which will be its own function, the Excess Heat Factor.\n",
    "\n",
    "    Ive realeased that I can save tiem and remove the EHI positive and EHFp as the EHIacc, EHIsig are only needed in the rest of the function.\n",
    "    I will have EHF avalaible to be used though.\n",
    "\n",
    "    In order for this to work properly we will have to reset index.\n",
    "    '''\n",
    "    Data_Range = Data_Range.reset_index()\n",
    "    '''This is an index range of 0 to length-1'''\n",
    "\n",
    "    ''' This is the Excess Heat Factor Function, developed by Nairn 2009'''\n",
    "    #Heatwaves events using a lag for heat-related health issues.\n",
    "    #EHF = Excess_Heat_Factor_Function(Data_Range,date_title,Column_Name,CDP,CDPColumn_Name)\n",
    "    #Heatwave events full\n",
    "    EHF = Excess_Heat_Factor_Function_v3(Data_Range,date_title,Column_Name,CDP,CDPColumn_Name)\n",
    "\n",
    "\n",
    "\n",
    "    return(EHF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d49939d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%The Heatwaves Perth\n",
    "def Proper_Heatwaves_Perth_v2(Data,Heatwave_MaxT,EHF_Min,date_name):\n",
    "    '''\n",
    "    Data: Dataframe\n",
    "        This is the daily maximum and minimum temperatures.\n",
    "    \n",
    "    Max_Heatwave: Dataframe\n",
    "        List of all heatwaves within the maxmimum temperature.\n",
    "    \n",
    "    Min_EHF: Dataframe\n",
    "        List of all heatwaves within the minimum temperature and its EHF value, which is vital to be checked for the \n",
    "        2 night criteria\n",
    "        \n",
    "    date_name: string\n",
    "        Name of column that you have for heatwave\n",
    "        \n",
    "    Output: Full_Heatwaves\n",
    "        This is the full heatwave list using the 3 max and 2 min definition of heatwaves. This only has the maximum and minimum, CDP,\n",
    "        and ... may have to add more.\n",
    "    '''\n",
    "    #Here we import the necessary packages\n",
    "    import pandas as pd\n",
    "    \n",
    "    #Now we import our maximum temperature only here, because the min for the \n",
    "    #two days must be YYN, YNY, NYY, therefore the min heatwace variant is actually irrelevent.\n",
    "    Max = Heatwave_MaxT\n",
    "    Data.set_index('date')\n",
    "    EHF_Min.set_index('date')\n",
    "    #Storing the heatwaves\n",
    "    Heatwave_Event = []\n",
    "    count = 1\n",
    "    ids = Max['id'].drop_duplicates( keep='first', inplace=False)\n",
    "\n",
    "    for i in ids:\n",
    "       #This extracts the id from the Max_Event\n",
    "       Max_Event = Max[Max['id']==i]\n",
    "       #Reset Index to extract the dates for the loc function in Data \n",
    "       Max_Event = Max_Event.reset_index() \n",
    "       #Find the 1st date and the 3rd date of the heatwave event in the max\n",
    "       start = Max_Event['date'][0]\n",
    "       end_Check = Max_Event['date'][2]\n",
    "       end = Max_E['date'][len(Max_E)-1]\n",
    "       #Gets the Min event to see it if it within the bounds of the max event, it is actually the criteria\n",
    "       #3 days and 2 nights,\n",
    "       Min_Check = EHF_Min.loc[start:end_Check]\n",
    "       #Here should have the minimum temperature EHF which should be positive for at least 2 days.\n",
    "       Min_Check = EHF_Min[EHF_Min['Excess Heat Factor'] >= 0 ]\n",
    "       \n",
    "       length = len(Min_Check)\n",
    "       #print((Percent,length))\n",
    "       \n",
    "       #Now extract the information for the period.\n",
    "       if(length >= 2):\n",
    "           Temperature = Temperature.loc[start:end]\n",
    "           Temperature['id'] = [count] * len(Temperature)\n",
    "           count = count + 1\n",
    "           Heatwave_Event.append(Temperature)\n",
    "           \n",
    "    Full_Heatwaves = pd.concat(Heatwave_Event,axis=0)\n",
    "      \n",
    "    return(Full_Heatwaves)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee511935",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50ea687",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9889c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f46888f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03733e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10ba243",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68823468",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09774d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c0fac6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83e2456",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21b4cbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dea33e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba82e8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6105977",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
