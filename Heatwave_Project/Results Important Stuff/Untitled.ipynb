{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98e2be26",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2492d85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Strictly_Functions_Project as STP\n",
    "\n",
    "from bisect import bisect_left\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\jarra\\Desktop\\Masters\\Heatwave_Project\")\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#RMSE \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from datetime import datetime\n",
    "import PT13_Functions_For_Masters_New_Test as HW_Func\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c26d422",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8bc3847",
   "metadata": {},
   "outputs": [],
   "source": [
    "P_Gardens = pd.read_csv(r\"E:\\LIBRARY\\UNIVERSITY\\Masters Research\\Python\\Data\\perthgardens_daily_1880-1900.csv\")\n",
    "P_Gardens_Corr = pd.read_csv(r\"E:\\LIBRARY\\UNIVERSITY\\Masters Research\\Python\\Data\\perthgardens_daily_corrected_1880-1900.csv\")\n",
    "\n",
    "#Now we need to go back in time and minus 200 years off the date\n",
    "#Convert To Datetime\n",
    "\n",
    "P_Gardens['time'] = pd.to_datetime(P_Gardens['time'],format=\"%d/%m/%Y\")\n",
    "P_Gardens_Corr['time'] = pd.to_datetime(P_Gardens_Corr['time'],format=\"%d/%m/%Y\")\n",
    "\n",
    "#Split the Year up\n",
    "\n",
    "P_Gardens = HW_Func.Date_Splitter(P_Gardens,'time',single= True)\n",
    "P_Gardens_Corr = HW_Func.Date_Splitter(P_Gardens_Corr,'time',single= True)\n",
    "P_Gardens['year'] = P_Gardens['year']-200\n",
    "P_Gardens_Corr['year'] = P_Gardens_Corr['year']-200\n",
    "#Combine in same format as ACORN-SAT\n",
    "\n",
    "cols=[\"year\",\"month\",\"day\"]\n",
    "P_Gardens['date'] = P_Gardens[cols].apply(lambda x: '-'.join(x.values.astype(str)), axis=\"columns\")\n",
    "P_Gardens_Corr['date'] = P_Gardens_Corr[cols].apply(lambda x: '-'.join(x.values.astype(str)), axis=\"columns\")\n",
    "\n",
    "del P_Gardens['time']\n",
    "del P_Gardens_Corr['time']\n",
    "del P_Gardens['year']\n",
    "del P_Gardens_Corr['year']\n",
    "del P_Gardens['month']\n",
    "del P_Gardens_Corr['month']\n",
    "del P_Gardens['day']\n",
    "del P_Gardens_Corr['day']\n",
    "\n",
    "P_Gardens['date'] = pd.to_datetime(P_Gardens['date'],format=\"%Y/%m/%d\")\n",
    "P_Gardens_Corr['date'] = pd.to_datetime(P_Gardens_Corr['date'],format=\"%Y/%m/%d\")\n",
    "\n",
    "#Max Temp, (drop(0) has dropped the 0th index, so it starts at 1)\n",
    "MaxT_Perth = pd.read_csv(r\"E:\\LIBRARY\\UNIVERSITY\\Masters Research\\Python\\Data\\UPDATED TMAX, TMIN ACORN-SAT\\tmax.009021.daily (3).csv\").drop(0)\n",
    "#Min Temp\n",
    "MinT_Perth = pd.read_csv(r\"E:\\LIBRARY\\UNIVERSITY\\Masters Research\\Python\\Data\\UPDATED TMAX, TMIN ACORN-SAT\\tmin.009021.daily (2).csv\").drop(0)\n",
    "#Ave Temp\n",
    "AvgT_Perth = (MaxT_Perth['maximum temperature (degC)']+MinT_Perth['minimum temperature (degC)'])/2\n",
    "\n",
    "Maximum = pd.Series(MaxT_Perth['maximum temperature (degC)'], name=\"Max\")\n",
    "Minimum = pd.Series(MinT_Perth['minimum temperature (degC)'],name=\"Min\")\n",
    "Average = pd.Series(AvgT_Perth,name=\"Avg\")\n",
    "\n",
    "#The Daily Max Min Ave Data\n",
    "ACORN_SAT = pd.concat([MaxT_Perth['date'],Maximum,Minimum,Average],axis=1)\n",
    "ACORN_SAT['date'] = pd.to_datetime(ACORN_SAT['date'],format=\"%Y/%m/%d\")\n",
    "\n",
    "\n",
    "\n",
    "#Now load in and fix Perth Gardens 1830-1875\n",
    "Per_Gard = pd.read_csv(r\"E:\\LIBRARY\\UNIVERSITY\\Masters Research\\Python\\Data\\swanriver_subdaily_1830-1875.csv\")\n",
    "Per_Gard\n",
    "#Set Datetime\n",
    "Per_Gard['date'] = pd.to_datetime(Per_Gard['date'],dayfirst = True)\n",
    "    \n",
    "\n",
    "#So this works, now we need to expand this into a for loop and make this a new dataframe to be added onto\n",
    "#the historical time because it will make things easier\n",
    "\n",
    "\n",
    "\n",
    "#Can't set index yet.\n",
    "#Perth Regional Office 1967 to 1992 sub daily dataset\n",
    "PRO_Sub = pd.read_csv(r\"E:\\LIBRARY\\UNIVERSITY\\Masters Research\\Python\\Data\\perthregionaloffice_subdaily_1942-1992.csv\")\n",
    "\n",
    "PRO_Sub['date'] = pd.to_datetime(PRO_Sub['date'],dayfirst = True)\n",
    "PRO_Sub = PRO_Sub.set_index('date')\n",
    "PRO_Sub =PRO_Sub['temp']/10 \n",
    "\n",
    "PRO_Sub_ES  = PRO_Sub.loc['1967':'1992']\n",
    "PRO_Sub_ES =PRO_Sub_ES\n",
    "\n",
    "## Perth Regional Office Daily Extreme Dataset\n",
    "#Load PRO in\n",
    "#BOM PERTH REGIONAL OFFICE\n",
    "MaxT_PRO = pd.read_csv(r\"E:\\LIBRARY\\UNIVERSITY\\Masters Research\\Python\\Data\\IDCJAC0010_009034_1800_Data.csv\")\n",
    "MinT_PRO = pd.read_csv(r\"E:\\LIBRARY\\UNIVERSITY\\Masters Research\\Python\\Data\\IDCJAC0011_009034_1800_Data.csv\")\n",
    "\n",
    "#Clean The data\n",
    "MaxT_PRO['Datetime']= pd.to_datetime(MaxT_PRO[['Year', 'Month', 'Day']])\n",
    "MinT_PRO['Datetime']= pd.to_datetime(MinT_PRO[['Year', 'Month', 'Day']])\n",
    "\n",
    "#Delete irrelevent columns\n",
    "del MaxT_PRO['Product code']\n",
    "del MaxT_PRO['Bureau of Meteorology station number']\n",
    "del MaxT_PRO['Year']\n",
    "del MaxT_PRO['Month']\n",
    "del MaxT_PRO['Day']\n",
    "del MaxT_PRO['Days of accumulation of maximum temperature']\n",
    "del MaxT_PRO['Quality']\n",
    "del MinT_PRO['Product code']\n",
    "del MinT_PRO['Bureau of Meteorology station number']\n",
    "del MinT_PRO['Year']\n",
    "del MinT_PRO['Month']\n",
    "del MinT_PRO['Day']\n",
    "del MinT_PRO['Days of accumulation of minimum temperature']\n",
    "del MinT_PRO['Quality']\n",
    "\n",
    "#Change the column name to date\n",
    "MaxT_PRO= MaxT_PRO.rename(columns={'Datetime':'date'})\n",
    "MinT_PRO= MinT_PRO.rename(columns={'Datetime':'date'})\n",
    "\n",
    "\n",
    "#Change the column names\n",
    "MaxT_PRO= MaxT_PRO.rename(columns={'Maximum temperature (Degree C)':'PRO Max'})\n",
    "MinT_PRO= MinT_PRO.rename(columns={'Minimum temperature (Degree C)':'PRO Min'})\n",
    "\n",
    "#Now concat it\n",
    "MaxT_PRO= MaxT_PRO.set_index('date')\n",
    "MinT_PRO= MinT_PRO.set_index('date')\n",
    "\n",
    "PRO_DE = pd.merge(left = MaxT_PRO,right  =MinT_PRO,left_index=True,right_index=True  )\n",
    "\n",
    "#Training Data\n",
    "PRO_DE_Training = PRO_DE.loc['1967':'1992']\n",
    "PRO_Sub_Training = PRO_Sub_ES\n",
    "#Estimating Data\n",
    "PRO_Sub_4_Est = PRO_Sub.reset_index()\n",
    "T_Ext =PRO_DE_Training.reset_index()\n",
    "T_Sub =PRO_Sub_ES.reset_index()\n",
    "S_Est = PRO_Sub_4_Est\n",
    "\n",
    "\n",
    "#Get the Max and Min Information\n",
    "MaxT_Perth = pd.read_csv(r\"E:\\LIBRARY\\UNIVERSITY\\Masters Research\\Python\\Data\\tmax.009021.daily.csv\").drop(0).reset_index(drop=True)\n",
    "MinT_Perth = pd.read_csv(r\"E:\\LIBRARY\\UNIVERSITY\\Masters Research\\Python\\Data\\tmin.009021.daily.csv\").drop(0).reset_index(drop=True)\n",
    "\n",
    "#Rename the columns\n",
    "Maximum = pd.Series(MaxT_Perth['maximum temperature (degC)'], name=\"Max\")\n",
    "Minimum = pd.Series(MinT_Perth['minimum temperature (degC)'],name=\"Min\")\n",
    "\n",
    "#Concat it all together\n",
    "Daily_MaxMin = pd.concat([MaxT_Perth['date'],Maximum,Minimum],axis=1)\n",
    "\n",
    "#Apply datetime\n",
    "Daily_MaxMin['date'] = pd.to_datetime(Daily_MaxMin['date'],format=\"%d/%m/%Y\")\n",
    "\n",
    "#Dates \n",
    "#This is used in the concatination process when the CDP is developed and other things \n",
    "#that have the data disappear. Since the full 366 days need to be accounted for, 2020 was \n",
    "#the year I chose for this\n",
    "#'''\n",
    "Dates = pd.read_csv(r\"E:\\LIBRARY\\UNIVERSITY\\Masters Research\\Python\\Data\\Dates, includes feb 29.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06814851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Max</th>\n",
       "      <th>Min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1830-04-16</td>\n",
       "      <td>27.007308</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1830-04-17</td>\n",
       "      <td>27.596920</td>\n",
       "      <td>14.997224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1830-04-18</td>\n",
       "      <td>29.487644</td>\n",
       "      <td>18.325167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1830-04-19</td>\n",
       "      <td>28.430873</td>\n",
       "      <td>19.324581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1830-04-20</td>\n",
       "      <td>26.218648</td>\n",
       "      <td>12.510398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16692</th>\n",
       "      <td>1875-12-28</td>\n",
       "      <td>39.010538</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16693</th>\n",
       "      <td>1875-12-29</td>\n",
       "      <td>36.075399</td>\n",
       "      <td>22.561407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16694</th>\n",
       "      <td>1875-12-30</td>\n",
       "      <td>33.140260</td>\n",
       "      <td>18.517799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16695</th>\n",
       "      <td>1875-12-31</td>\n",
       "      <td>27.374808</td>\n",
       "      <td>19.369610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16696</th>\n",
       "      <td>1876-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.587498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16697 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date        Max        Min\n",
       "0     1830-04-16  27.007308        NaN\n",
       "1     1830-04-17  27.596920  14.997224\n",
       "2     1830-04-18  29.487644  18.325167\n",
       "3     1830-04-19  28.430873  19.324581\n",
       "4     1830-04-20  26.218648  12.510398\n",
       "...          ...        ...        ...\n",
       "16692 1875-12-28  39.010538        NaN\n",
       "16693 1875-12-29  36.075399  22.561407\n",
       "16694 1875-12-30  33.140260  18.517799\n",
       "16695 1875-12-31  27.374808  19.369610\n",
       "16696 1876-01-01        NaN  17.587498\n",
       "\n",
       "[16697 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_1830_1875_All = STP.Temp_Estimation(Per_Gard, T_Sub, T_Ext, 1)\n",
    "#Extract TriaL 1\n",
    "Data_1830_1875 = Data_1830_1875_All.get(\"Trial_1\")\n",
    "\n",
    "#Delete The correlations\n",
    "del Data_1830_1875['Correlation Max T']\n",
    "del Data_1830_1875['Correlation Min T']\n",
    "\n",
    "#rename\n",
    "Data_1830_1875 = Data_1830_1875.rename(columns={'Max Temp Estimation': 'Max','Min Temp Estimation': 'Min' })\n",
    "Data_1830_1875 = Data_1830_1875.reset_index()\n",
    "Data_1830_1875 \n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f82f23df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ACORN_SAT_1910_2021\n",
    "Daily_MaxMin = Daily_MaxMin.set_index('date')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "234f3f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Max</th>\n",
       "      <th>Min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1830-04-16</td>\n",
       "      <td>27.007308</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1830-04-17</td>\n",
       "      <td>27.596920</td>\n",
       "      <td>14.997224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1830-04-18</td>\n",
       "      <td>29.487644</td>\n",
       "      <td>18.325167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1830-04-19</td>\n",
       "      <td>28.430873</td>\n",
       "      <td>19.324581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1830-04-20</td>\n",
       "      <td>26.218648</td>\n",
       "      <td>12.510398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69833</th>\n",
       "      <td>2021-06-26</td>\n",
       "      <td>20.300000</td>\n",
       "      <td>5.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69834</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>15.600000</td>\n",
       "      <td>8.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69835</th>\n",
       "      <td>2021-06-28</td>\n",
       "      <td>19.700000</td>\n",
       "      <td>10.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69836</th>\n",
       "      <td>2021-06-29</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>12.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69837</th>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>16.800000</td>\n",
       "      <td>7.700000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69838 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date        Max        Min\n",
       "0     1830-04-16  27.007308        NaN\n",
       "1     1830-04-17  27.596920  14.997224\n",
       "2     1830-04-18  29.487644  18.325167\n",
       "3     1830-04-19  28.430873  19.324581\n",
       "4     1830-04-20  26.218648  12.510398\n",
       "...          ...        ...        ...\n",
       "69833 2021-06-26  20.300000   5.800000\n",
       "69834 2021-06-27  15.600000   8.700000\n",
       "69835 2021-06-28  19.700000  10.500000\n",
       "69836 2021-06-29  18.000000  12.500000\n",
       "69837 2021-06-30  16.800000   7.700000\n",
       "\n",
       "[69838 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Create a new dataframe with a column for every day between 1835-04-16 and 2021-01-01\n",
    "start_date = pd.to_datetime('1830-04-16')\n",
    "end_date = pd.to_datetime('2021-06-30')\n",
    "date_range = pd.date_range(start_date, end_date, freq='D')\n",
    "df_dates = pd.DataFrame({'date': date_range})\n",
    "df_dates\n",
    "# Merge the new dataframe with the two existing dataframes using a left join\n",
    "df_merged = pd.merge(df_dates, Data_1830_1875[['date', 'Max', 'Min']], on='date', how='left')\n",
    "#df_merged = pd.merge(df_merged[['date', 'Max', 'Min']], Daily_MaxMin[['date', 'Max', 'Min']], on='date', how='left')\n",
    "df_merged = df_merged.set_index('date')\n",
    "# Fill any missing values with the last known value (forward fill)\n",
    "#df_merged.fillna(method='ffill', inplace=False)\n",
    "df_concat = pd.concat([df_merged,Daily_MaxMin],axis =0)\n",
    "df_concat = df_concat.reset_index()\n",
    "df_concat = df_concat.drop_duplicates(subset=[\"date\"], keep='last')\n",
    "df_concat = df_concat.set_index('date')\n",
    "df_concat.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5734ccb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4d0492",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = df_concat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85539968",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .dt accessor with datetimelike values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m Heatwaves,CDP \u001b[38;5;241m=\u001b[39m \u001b[43mSTP\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHeatwave_Function_v4\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_concat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mDates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mCDP_Matrix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mHeatwave_Detail\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mPercentile\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m85\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mCDP_start_end_years\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1961\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1990\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\Masters\\Heatwave_Project\\Results Important Stuff\\Strictly_Functions_Project.py:1082\u001b[0m, in \u001b[0;36mHeatwave_Function_v4\u001b[1;34m(Dataset, Dates_DataFrame, CDP_Matrix, Heatwave_Detail, Percentile, window, CDP_start_end_years)\u001b[0m\n\u001b[0;32m   1079\u001b[0m Column_Dataset \u001b[38;5;241m=\u001b[39m Dataset\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m   1081\u001b[0m \u001b[38;5;66;03m#For the calendar day percentile (CDP) function this dataset needs to be expanded to dataset_exp\u001b[39;00m\n\u001b[1;32m-> 1082\u001b[0m Dataset_Exp \u001b[38;5;241m=\u001b[39m \u001b[43mDate_Splitter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1084\u001b[0m \u001b[38;5;66;03m#Now calculate the Calender Day Percentiles for tmax and tmin if required.\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mlen\u001b[39m(CDP_Matrix) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;66;03m#Now to calculate the CDP for Max and Min Temperatures\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\Masters\\Heatwave_Project\\Results Important Stuff\\Strictly_Functions_Project.py:1179\u001b[0m, in \u001b[0;36mDate_Splitter\u001b[1;34m(Dataset)\u001b[0m\n\u001b[0;32m   1177\u001b[0m Column_Dataset \u001b[38;5;241m=\u001b[39m Dataset\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m   1178\u001b[0m \u001b[38;5;66;03m#Split the data into year, month and day\u001b[39;00m\n\u001b[1;32m-> 1179\u001b[0m Dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m\u001b[43mDataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mColumn_Dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdt\u001b[49m\u001b[38;5;241m.\u001b[39myear\n\u001b[0;32m   1180\u001b[0m Dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmonth\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mDataset[Column_Dataset[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mmonth\n\u001b[0;32m   1181\u001b[0m Dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mday\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;241m=\u001b[39mDataset[Column_Dataset[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mday\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MASTERS_JARRAD\\lib\\site-packages\\pandas\\core\\generic.py:5575\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   5569\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   5570\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   5571\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   5572\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   5573\u001b[0m ):\n\u001b[0;32m   5574\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 5575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MASTERS_JARRAD\\lib\\site-packages\\pandas\\core\\accessor.py:182\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[1;34m(self, obj, cls)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor\n\u001b[1;32m--> 182\u001b[0m accessor_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;66;03m# NDFrame\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MASTERS_JARRAD\\lib\\site-packages\\pandas\\core\\indexes\\accessors.py:509\u001b[0m, in \u001b[0;36mCombinedDatetimelikeProperties.__new__\u001b[1;34m(cls, data)\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_period_dtype(data\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m    507\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m PeriodProperties(data, orig)\n\u001b[1;32m--> 509\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only use .dt accessor with datetimelike values\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can only use .dt accessor with datetimelike values"
     ]
    }
   ],
   "source": [
    "\n",
    "Heatwaves,CDP = STP.Heatwave_Function_v4(df_concat,\n",
    "                         Dates,\n",
    "                         CDP_Matrix = [],\n",
    "                         Heatwave_Detail= True,\n",
    "                         Percentile = 85,\n",
    "                         window = 7,\n",
    "                         CDP_start_end_years = [1961,1990])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebdda0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c2f49b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98c8da8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3737bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb03653",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e909e4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
