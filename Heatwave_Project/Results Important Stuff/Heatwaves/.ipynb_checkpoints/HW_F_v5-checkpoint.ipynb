{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecbe818d",
   "metadata": {},
   "source": [
    "# HEATWAVE FUNCTION FINAL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdc0f23",
   "metadata": {},
   "source": [
    "## 1 Heatwave Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c5b5443",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Core Function\n",
    "def Heatwave_Function_v5(Dataset,Dates_DataFrame,CDP_Matrix,Heatwave_Detail= True,Percentile = 85,window = 7,CDP_start_end_years = [1961,1990]):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    Dataset : DataFrame\n",
    "        A Tmax and Tmin Dataset that has index as numbers and not datetime.\n",
    "        #It should be in column form date_name, Tmax, Tmin\n",
    "        datetime should be in format Year-Month-Day Already\n",
    "        \n",
    "    Dates_DataFrame : DataFrame\n",
    "        This is just a DataFrame that has the dates of 366 days ready to be used where needed. \n",
    "    \n",
    "    CDP_Matrix : Array\n",
    "        If set to [] then the functions and arguements relating to the CDP are irrelevant to the function by inputs should be\n",
    "        for the function to work properly.\n",
    "    \n",
    "    Heatwave_Detail : True or False\n",
    "        If True is selected the heatwaves will be expanded into more detail.\n",
    "        \n",
    "    Percentile : Integer/Decimal\n",
    "        A number that is used for the CDP, it calculates the value where the temperature must exceed to be in \n",
    "        that x percentile\n",
    "    \n",
    "    \n",
    "    window : Integer\n",
    "        Number of days either side of the day in focus that is used to calculate the percentile value in the CDP\n",
    "    \n",
    "    CDP_start_end_years : array of 2\n",
    "        The years when the CDP should be calculated. Forms the basis of how many heatwaves we get\n",
    "    \n",
    "    RETURNS\n",
    "    -----------------\n",
    "    \n",
    "    heatwaves : DataFrame\n",
    "        The heatwave with all the relevant information.\n",
    "        \n",
    "    CDP : DataFrame\n",
    "        Calendar Day Percentile so this can be inputted in the function again and save time.\n",
    "    \n",
    "    '''\n",
    "    #Extract Columns\n",
    "    Column_Dataset = Dataset.columns\n",
    "        #For the calendar day percentile (CDP) function this dataset needs to be expanded to dataset_exp\n",
    "    Dataset_Exp = Date_Splitter(Dataset)\n",
    "    \n",
    "    #Now calculate the Calender Day Percentiles for tmax and tmin if required.\n",
    "    if (len(CDP_Matrix) == 0):\n",
    "        #Now to calculate the CDP for Max and Min Temperatures\n",
    "        CDP_Max = Calendar_Day_Percentile(Dataset_Exp,Percentile,\n",
    "                                      Column_Dataset[1],\n",
    "                                      CDP_start_end_years[0],\n",
    "                                      CDP_start_end_years[1],\n",
    "                                      window,\n",
    "                                      Dates_DataFrame)\n",
    "    \n",
    "        CDP_Min = Calendar_Day_Percentile(Dataset_Exp,Percentile,\n",
    "                                      Column_Dataset[2],\n",
    "                                      CDP_start_end_years[0],\n",
    "                                      CDP_start_end_years[1],\n",
    "                                      window,\n",
    "                                      Dates_DataFrame)\\\n",
    "        #Concat the tmax and tmax CDPs together\n",
    "        CDP_Max_Col = CDP_Max.columns \n",
    "        CDP_Min_Col = CDP_Min.columns \n",
    "        CDP = pd.concat([CDP_Max[CDP_Max_Col[0]],CDP_Max[CDP_Max_Col[1]],CDP_Min[CDP_Min_Col[1]]],axis=1) #Change the name\n",
    "    else:\n",
    "        CDP = CDP_Matrix\n",
    "    \n",
    "    \n",
    "    # Now using all the information, generate the Excess Heat Factor Values\n",
    "    #Lets make it simpler and calculate the EHF which has the components of EHI sig and EHI acc\n",
    "    EHF_Max, EHF_Min = EXCESS_HEAT_FACTOR(Dataset, CDP)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##############UP TO HERE ON MY EXPLANATION AND FIXING.\n",
    "    #Combine all the data together in 1 big dataset\n",
    "    #Make all datetime set\n",
    "    Dataset_Date =  Dataset.set_index(Column_Dataset[0])\n",
    "    #This is finding the highest and lowest year within the dataset\n",
    "    Start_end_year = [Dataset_Date['year'].min(),Dataset_Date['year'].max()]\n",
    "    \n",
    "    #Clean the Dataset_Date up a bit \n",
    "    del Dataset_Date['year'] \n",
    "    del Dataset_Date['month']\n",
    "    del Dataset_Date['day'] \n",
    "    \n",
    "    #Remane the EHF columns so its max and min categorised\n",
    "    EHF_Max_Min_Col = EHF_Max.columns\n",
    "    EHF_Max = EHF_Max.rename(columns={EHF_Max_Min_Col[1]:EHF_Max_Min_Col[1] + '{}'.format('Max')})\n",
    "    EHF_Max = EHF_Max.rename(columns={EHF_Max_Min_Col[2]:EHF_Max_Min_Col[2] + '{}'.format('Max')})\n",
    "    EHF_Max = EHF_Max.rename(columns={EHF_Max_Min_Col[3]:EHF_Max_Min_Col[3] + '{}'.format('Max')})\n",
    "    EHF_Max_Date =  EHF_Max.set_index(EHF_Max_Min_Col[0])\n",
    "    EHF_Min = EHF_Min.rename(columns={EHF_Max_Min_Col[1]:EHF_Max_Min_Col[1] + '{}'.format('Min')})\n",
    "    EHF_Min = EHF_Min.rename(columns={EHF_Max_Min_Col[2]:EHF_Max_Min_Col[2] + '{}'.format('Min')})\n",
    "    EHF_Min = EHF_Min.rename(columns={EHF_Max_Min_Col[3]:EHF_Max_Min_Col[3] + '{}'.format('Min')})\n",
    "    EHF_Min_Date =  EHF_Min.set_index(EHF_Max_Min_Col[0])\n",
    "    \n",
    "    \n",
    "    #Add all the data together and the columns should be and this will get the data usable for the final functions.\n",
    "    '''\n",
    "    index \\ date \\ Max \\ Min \\ Excess Heat Factor Max \\ Heat Stress Max \\ Excess Heat Max \\ Excess Heat Factor Min \\ Heat Stress Min \\ Excess Heat Min \n",
    "    '''\n",
    "    Full_Information_Vector = pd.concat([Dataset_Date, EHF_Max_Date, EHF_Min_Date],axis=1)\n",
    "    Full_Information_Vector = Full_Information_Vector.reset_index()\n",
    "        #Generate the binary\n",
    "    Full_Information_Vector['EHFMx_Bin'] = Full_Information_Vector['Excess Heat FactorMax'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    Full_Information_Vector['EHFMn_Bin'] = Full_Information_Vector['Excess Heat FactorMin'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    Full_Information_Vector['EHMx_Bin'] = Full_Information_Vector['Excess HeatMax'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    Full_Information_Vector['EHMn_Bin'] = Full_Information_Vector['Excess HeatMin'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    #Sum together\n",
    "    Full_Information_Vector['EH_Bin'] = Full_Information_Vector['EHMx_Bin'] + Full_Information_Vector['EHMn_Bin']\n",
    "    Full_Information_Vector['EHF_Bin'] = Full_Information_Vector['EHFMx_Bin'] + Full_Information_Vector['EHFMn_Bin']\n",
    "    \n",
    "    \n",
    "    \n",
    "    Heatwave_Finder = Full_Information_Vector[['date','EHFMx_Bin','EHF_Bin','EH_Bin']]\n",
    "    # Calculate the 3-moving sum\n",
    "    Heatwave_Finder['EHFMx_3Sum'] = Heatwave_Finder['EHFMx_Bin'].rolling(window=3, min_periods=1, center=False).sum()\n",
    "    Heatwave_Finder['EHF_3Sum'] = Heatwave_Finder['EHF_Bin'].rolling(window=3, min_periods=1, center=False).sum()\n",
    "\n",
    "    \n",
    "    #Calculate both heatwaves and warmwaves\n",
    "    Warm_Spells_Matrix = Warmwaves(Full_Information_Vector,Heatwave_Finder)\n",
    "    \n",
    "    #Find the heatwaves with loose ends at the start of Nov and end of Mar\n",
    "    heatwaves = Heatwave_Function(Warm_Spells_Matrix)\n",
    "    \n",
    "    #Generate an extended form of the heatwave table if required.\n",
    "    if(Heatwave_Detail == True):\n",
    "        heatwaves = Heatwave_Table_Generator(heatwaves,heatwaves_data)\n",
    "    return(heatwaves,heatwaves_data,CDP,Full_Information_Vector)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee4d432",
   "metadata": {},
   "source": [
    "## 2 Date Splitter Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "975cf512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Date_Splitter(Dataset):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    Data : Dataframe \n",
    "        CSV dataframe where the data is from.\n",
    "        \n",
    "    date_title : String\n",
    "        Datetime Column Name for the extraction\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Dataset : DataFrame\n",
    "        DataFrame that has 3 new columns for Year Month and Day\n",
    "\n",
    "    '''\n",
    "    #Exctract all the columns, but the one we need is column 0\n",
    "    Column_Dataset = Dataset.columns\n",
    "    #Split the data into year, month and day\n",
    "    Dataset['year'] =Dataset[Column_Dataset[0]].dt.year\n",
    "    Dataset['month']=Dataset[Column_Dataset[0]].dt.month\n",
    "    Dataset['day']  =Dataset[Column_Dataset[0]].dt.day\n",
    "    return(Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cf6d7b",
   "metadata": {},
   "source": [
    "## 3 Calendar Day Percentile Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33167324",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Calendar_Day_Percentile(Data,Percentile,Column_Name,start_year,end_year, window, Dates_DataFrame):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    Data : Dataframe \n",
    "        The DataFrame in the expanded date form with year, month and day done already.\n",
    "        \n",
    "    Percentile : Integer/Decimal\n",
    "        A number that is used for the CDP, it calculates the value where the temperature must exceed to be in \n",
    "        that x percentile\n",
    "        \n",
    "    Column_Name : String\n",
    "        Determines if we are working out max or min temperatures\n",
    "        \n",
    "    start_year : Integer\n",
    "        Year you want to start the CDP from\n",
    "        \n",
    "    end_year : Integer\n",
    "        Year you want to end the CDP from\n",
    "        \n",
    "    Dates_DataFrame : DataFrame\n",
    "        These are the 366 total days that the CDP function will append to so we can extract a day and month in the future\n",
    "        when caculating the Excess Heat Factor\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    CDP : DataFrame\n",
    "        Calendar Day Percentile of the entire year from the baseline and window chsoen in DataFrame format\n",
    "\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    Start and end Years for the values to use\n",
    "    Start Year will be Nov - 1911 to Mar - 1942\n",
    "    I will classify a year heatwave as the 1911 season as Nov-1911 to Mar-1912\n",
    "\n",
    "    Years to be excluded from the data:\n",
    "    1910 and 2021 as these are incomplete\n",
    "\n",
    "    In the 1880-1900\n",
    "    This will be a different\n",
    "    '''\n",
    "    Data = Date_Splitter(Data)\n",
    "\n",
    "    \n",
    "    \n",
    "    #Extract Columns \n",
    "    Column_Dataset = Data.columns\n",
    "    \n",
    "    #Set Index to Date\n",
    "    Data_Extracted = Data.set_index(Column_Dataset[0])\n",
    "    \n",
    "    #Extract the Start and End Year only and since we are starting from Summer and ending \n",
    "    #Lets go from 1911 - 1 December to 1940 - November as an example\n",
    "    \n",
    "    #Extract the Summer of first year to Last month of spring of the last year\n",
    "    Data_Extracted = Data_Extracted.loc['{}-12-01'.format(start_year-1):'{}-11-30'.format(end_year)]\n",
    "    \n",
    "    #Group By month and day\n",
    "    group_days = Data_Extracted.groupby(['month','day'])\n",
    "    Daily_Data= []\n",
    "    \n",
    "    #Now using the month and daily data for each of the 366 days put them in their separate bins\n",
    "    for groups,days in group_days:\n",
    "        #Extract the specified day bin\n",
    "        Dailypre = group_days.get_group(groups).reset_index()\n",
    "        #Get the maximum values for the entire record for that calendar day\n",
    "        Values= Dailypre[Column_Name]\n",
    "        #Make it a dataframe so it is appendable\n",
    "        Values = Values.to_frame()\n",
    "        #Append that bin to that day so there will be 366 bins with  x years of data\n",
    "        Daily_Data.append(Values[Column_Name])\n",
    "            \n",
    "        \n",
    "    #Now The Daily_Data has been done, we can then apply the CDP onto the bins for a window and estimate the value for the \n",
    "    #percentile\n",
    "    CalendarDay = TnX_Rolling(window, Daily_Data, Percentile)\n",
    "    \n",
    "    #Clean the data up\n",
    "    CDP = pd.DataFrame(CalendarDay, columns = [Column_Name])\n",
    "    CDP = pd.concat([Dates_DataFrame,CDP],axis=1)\n",
    "    CDP['date'] = pd.to_datetime(CDP['date'],format=\"%d/%m/%Y\")\n",
    "\n",
    "        \n",
    "    return(CDP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe7fe86",
   "metadata": {},
   "source": [
    "### 3.1 Tnx Rolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35344aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def TnX_Rolling(Window ,Dataset, Percentile):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    Window : Integer\n",
    "        How many days before AND after that the CDP will use up\n",
    "        \n",
    "    Dataset : DataFrame\n",
    "        It is the Daily_Data dataset that will be used from 3.\n",
    "    \n",
    "    Percentile : Integer/Decimal\n",
    "        It is the percentile the temperature must reaach to be accepted\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        TnX : Series\n",
    "        Array of length 366 of the CDP values.\n",
    "\n",
    "    '''\n",
    "    \n",
    "    #Since we are using the quantile version we start with that, same as percentile just 100 times less.\n",
    "    percent_to_quant = Percentile/100\n",
    "    \n",
    "    \n",
    "    TnX = []\n",
    "    #Ignore warnings cause we all know its a pain in the buttox\n",
    "    warnings.filterwarnings('ignore')  \n",
    "    \n",
    "    \n",
    "    #Lets begin with the central day so this will then be looped around and extracts each calendar day starting with 01-01\n",
    "    for central_day in range(366):\n",
    "        Temp_Storage = []\n",
    "        #The reason its 366 because it goes from 0 to 365 which is still length of 366\n",
    "        #Now to make the loop around the day in focus and append this to the central day  \n",
    "        \n",
    "        for around_days in range(0,Window+1):\n",
    "            #First make the if statement of central_day\n",
    "            if (around_days == 0):\n",
    "                #Add the data to a storage to be used\n",
    "                Temp_Storage = Dataset[central_day].to_numpy()\n",
    "            else:\n",
    "                #This is to check the windows for the other 365 days, if <0 or >365, then it extracts it from <=365 or >=0 \n",
    "                #Lets start with the addition of the window so central_day + window\n",
    "                if ((central_day + around_days) > 365):\n",
    "                    Window_Early_Year =  central_day + around_days - 366\n",
    "                    #Append this to the Temp_Storage\n",
    "                    Temp_Storage = np.concatenate((Temp_Storage, Dataset[Window_Early_Year].to_numpy()),axis =0)\n",
    "                    #Append the negative version to the Temp_Storage\n",
    "                    Temp_Storage = np.concatenate((Temp_Storage, Dataset[central_day - around_days].to_numpy()),axis =0)\n",
    "\n",
    "                elif ((central_day - around_days < 0)):\n",
    "                    Window_Late_Year =  central_day - around_days + 366\n",
    "                    #Append this to the Temp_Storage\n",
    "                    Temp_Storage = np.concatenate((Temp_Storage, Dataset[Window_Late_Year].to_numpy()),axis =0)\n",
    "                    #Append the negative version to the Temp_Storage\n",
    "                    Temp_Storage = np.concatenate((Temp_Storage, Dataset[central_day + around_days].to_numpy()),axis =0)\n",
    "                    \n",
    "                else:\n",
    "                    #If within bounds append normally\n",
    "                    Temp_Storage = np.concatenate((Temp_Storage, Dataset[central_day + around_days].to_numpy()),axis =0)\n",
    "                    Temp_Storage = np.concatenate((Temp_Storage, Dataset[central_day - around_days].to_numpy()),axis =0)\n",
    "\n",
    "        #Create a for loop that uses the YearTempData and find the percentile for that calendar based value.\n",
    "        #Now calculate the Percentile \n",
    "        Tn = np.quantile(Temp_Storage[~np.isnan(Temp_Storage)], percent_to_quant)#Have a llok properly and code it myslef and pull out ranks and find 90th percentile\n",
    "        TnX.append(Tn)\n",
    "    return(TnX) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e84005f",
   "metadata": {},
   "source": [
    "## 4. Excess Heat Factor Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce0dd39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EXCESS_HEAT_FACTOR(Data, CDP_Data):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        Dataset : DataFrame\n",
    "            A Tmax and Tmin Dataset that has index as numbers and not datetime.\n",
    "            It should be in column form date_name, Tmax, Tmin\n",
    "            datetime should be in format Year-Month-Day Already\n",
    "        \n",
    "        CDP_Data : DataFrame\n",
    "            The calendar day percentile based off a percetnile where the temperature needs to reach to be in that percentile.\n",
    "        \n",
    "        Returns \n",
    "        ----------\n",
    "        Excess_Heat_Stress_Factor_Matrix_Max : DataFrame\n",
    "            A DataFrame that includes the Excess Heat, Heat Stress and Excess Heat Factor variables for the tmax\n",
    "        \n",
    "        Excess_Heat_Stress_Factor_Matrix_Min : DataFrame\n",
    "            A DataFrame that includes the Excess Heat, Heat Stress and Excess Heat Factor variables for the tmax\n",
    "\n",
    "        \n",
    "        '''\n",
    "        #Extract the columsn of the Data and CDP\n",
    "        Data_col = Data.columns\n",
    "        CDP_col = CDP_Data.columns\n",
    "        \n",
    "        #Extract the date title\n",
    "        Data_Date = Data_col[0]\n",
    "        CDP_Date = CDP_col[0]\n",
    "        \n",
    "        #Set the index to dateData_Date\n",
    "        Data_Date_I = Data.set_index(Data_Date)\n",
    "        CDP_Date_I = CDP_Data.set_index(Data_Date)\n",
    "        \n",
    "        #Now we need to set the data with the start and end year to what is specified.\n",
    "        #Since the extended Summer begins in November and ends in March and the EHIacc needs a 30 day average prior to the \n",
    "        #i-2 so this means from the 1-11-XXXX we need to go back 33 days prior. This sets us to 29-9-XXXX.\n",
    "        #Data_Range = Data_Date_I.loc['{}-09-29'.format(start_end_years[0]):'{}-04-30'.format(start_end_years[1]+1)]\n",
    "        \n",
    "        #Now we have the necessary data to work out the EHIsig, EHIacc and EHF for both Max, Min and ?Average?\n",
    "        #Heat_Stress\n",
    "        EHIacc_Max = Heat_Stress(Data_Date_I, Data_col[1]) \n",
    "        EHIacc_Min = Heat_Stress(Data_Date_I, Data_col[2]) \n",
    "\n",
    "        #Excess Heat\n",
    "        EHIsig_Max = Excess_Heat(CDP_Date_I,CDP_col[1], Data_Date_I, Data_col[1]) \n",
    "        EHIsig_Min = Excess_Heat(CDP_Date_I,CDP_col[2], Data_Date_I, Data_col[2]) \n",
    "        Excess_Heat_Stress_Matrix_Max = pd.merge(EHIacc_Max,EHIsig_Max,how='left',on = [Data_Date])\n",
    "        Excess_Heat_Stress_Matrix_Min = pd.merge(EHIacc_Min,EHIsig_Min,how='left',on = [Data_Date])\n",
    "        \n",
    "        #Excess Heat Factor\n",
    "        EHF_Max = Excess_Heat_Factor_Calculator(Excess_Heat_Stress_Matrix_Max)\n",
    "        EHF_Min = Excess_Heat_Factor_Calculator(Excess_Heat_Stress_Matrix_Min)\n",
    "        \n",
    "        #Combine\n",
    "        Excess_Heat_Stress_Factor_Matrix_Max = pd.merge(EHF_Max,Excess_Heat_Stress_Matrix_Max,how='left',on = [Data_Date])\n",
    "        Excess_Heat_Stress_Factor_Matrix_Min = pd.merge(EHF_Min,Excess_Heat_Stress_Matrix_Min,how='left',on = [Data_Date])\n",
    "    \n",
    "        return(Excess_Heat_Stress_Factor_Matrix_Max,Excess_Heat_Stress_Factor_Matrix_Min)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425087dd",
   "metadata": {},
   "source": [
    "### 4.1 Heat Stress Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39ac0183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Heat_Stress(Data, Max_Min_Ave_Col):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    Data : DataFrame\n",
    "        This has the datetime as the index\n",
    "    \n",
    "    Max_Min_Col : Array\n",
    "        The choose of choosing the max or min or average column to use from the dataset\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    EHIacc_vector :  DataFrame\n",
    "        The Heat Stress DataFrame\n",
    "    '''\n",
    "    #Extract the column\n",
    "    Extracted_Data = Data[Max_Min_Ave_Col]\n",
    "    \n",
    "    #Reset the index to calculate the averages\n",
    "    Extracted_Data = Extracted_Data.reset_index()\n",
    "    Extracted_Data_col = Extracted_Data.columns\n",
    "    #Necessary Columns to append\n",
    "    #A date column\n",
    "    date_Values = []\n",
    "    #EHIacc column\n",
    "    EHIacc = []\n",
    "    \n",
    "    #Do the for loop\n",
    "    for dt in np.arange(Extracted_Data.index[0]+33,len(Data)):\n",
    "        #Extract the date index\n",
    "        Date = Extracted_Data[Extracted_Data_col[0]].loc[dt]\n",
    "        \n",
    "        #3-day mean where the day in focus is i\n",
    "        #But we need a checker to make sure all values are present\n",
    "        length_3day = len(Extracted_Data[Max_Min_Ave_Col].loc[dt-2:dt].dropna())\n",
    "        if (length_3day < 3):\n",
    "            mean_3_day = np.nan\n",
    "        else:\n",
    "            mean_3_day = Extracted_Data[Max_Min_Ave_Col].loc[dt-2:dt].mean()\n",
    "            \n",
    "        #3 to 32 day mean\n",
    "        #Now a dropna of 75% of values there means we can still work out the average\n",
    "        length_30day = len(Extracted_Data[Max_Min_Ave_Col].loc[dt-32:dt-3].dropna())\n",
    "        \n",
    "        if (length_30day < 23):\n",
    "            mean_30_day = np.nan\n",
    "        else:\n",
    "            mean_30_day = Extracted_Data[Max_Min_Ave_Col].loc[dt-32:dt-3].dropna().mean()\n",
    "        #The individual heat stress value\n",
    "        Heat_Stress_Value = mean_3_day - mean_30_day\n",
    "        #Append the date and Heat Stress Value\n",
    "        date_Values.append(Date)\n",
    "        EHIacc.append(Heat_Stress_Value)\n",
    "    \n",
    "    #Name the terms and combine\n",
    "    EHIacc = pd.DataFrame(EHIacc,columns=['Heat Stress'])\n",
    "    date_Values = pd.DataFrame(date_Values,columns=[Extracted_Data_col[0]])\n",
    "    \n",
    "    EHIacc_vector = pd.concat([date_Values, EHIacc],axis=1)\n",
    "    \n",
    "    return(EHIacc_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ba2f5f",
   "metadata": {},
   "source": [
    "### 4.2 Excess Heat Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a971870e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Excess_Heat(CDP,CDP_max_min_ave, Data, Max_Min_Ave_Col):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    CDP : DataFrame\n",
    "        The calendar day percentile based off a percetnile where the temperature needs to reach to be in that percentile.\n",
    "    \n",
    "    CDP_max_min_ave : string\n",
    "        The choose of choosing the max or min or average column to use from the CDP dataset\n",
    "     \n",
    "    Data : DataFrame\n",
    "        This has the datetime as the index\n",
    "    \n",
    "    Max_Min_Col : string\n",
    "        The choose of choosing the max or min or average column to use from the Data dataset\n",
    "    \n",
    "    Return\n",
    "    ---------\n",
    "    EHIsig_vector :  DataFrame\n",
    "        The Excess Heat DataFrame\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Reset the index to calculate the averages of the data\n",
    "    Extracted_Data = Data.reset_index()\n",
    "    Extracted_Data_col = Extracted_Data.columns\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #Necessary Columns to append\n",
    "    #A date column\n",
    "    date_Values = []\n",
    "    #EHIsig column\n",
    "    EHIsig = []\n",
    "    \n",
    "    #Do the for loop\n",
    "    for dt in np.arange(Extracted_Data.index[0]+33,len(Data)):\n",
    "        \n",
    "    \n",
    "        #Extract the date index\n",
    "        Date = Extracted_Data[Extracted_Data_col[0]].loc[dt]\n",
    "        \n",
    "        #Extract the date in the CDP column, we know the year is 2020\n",
    "        CDP_day = CDP[CDP_max_min_ave].loc['2020-{}-{}'.format(Date.month,Date.day)]\n",
    "             \n",
    "        Excess_Heat_Value = Extracted_Data[Max_Min_Ave_Col].loc[dt] -  CDP_day\n",
    "                                                       \n",
    "\n",
    "        #Append the date and Heat Stress Value\n",
    "        date_Values.append(Date)\n",
    "        EHIsig.append(Excess_Heat_Value)\n",
    "    \n",
    "    #Name the terms and combine\n",
    "    EHIsig = pd.DataFrame(EHIsig,columns=['Excess Heat'])\n",
    "    date_Values = pd.DataFrame(date_Values,columns=[Extracted_Data_col[0]])\n",
    "    \n",
    "    EHIsig_vector = pd.concat([date_Values, EHIsig],axis=1)\n",
    "    \n",
    "    \n",
    "    return(EHIsig_vector)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55909ed1",
   "metadata": {},
   "source": [
    "### 4.3 Excess Heat Factor Calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82f53edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Excess_Heat_Factor_Calculator(Excess_Heat_Stress_Matrix):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    Excess_Heat_Stress_Matrix : DataFrame\n",
    "        This is a DataFrame that combines the Excess Heat, Heat Stress together in one DataFrame\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    EHF_vector : DataFrame\n",
    "        This is the combination of the Excess Heat and Heat Stress as a value for each day.\n",
    "    \n",
    "    '''\n",
    "    EH_col = Excess_Heat_Stress_Matrix.columns\n",
    "    #Col 0 : Date name, Col 1: Heat Stress Col 2: Excess Heat\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Necessary Columns to append\n",
    "    #A date column\n",
    "    date_Values = []\n",
    "    #EHIsig column\n",
    "    EHF = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #Make sure when there are 2 positive it remains positive, if there are two negatives it remains negative \n",
    "    #and if one pos and one neg it remains negative\n",
    "    for dt in np.arange(Excess_Heat_Stress_Matrix.index[0],len(Excess_Heat_Stress_Matrix)):\n",
    "    \n",
    "        #Extract the date index\n",
    "        Date = Excess_Heat_Stress_Matrix[EH_col[0]].loc[dt]\n",
    "        \n",
    "        #Get the Heat Stress Term\n",
    "        HS = Excess_Heat_Stress_Matrix[EH_col[1]].loc[dt]\n",
    "        \n",
    "        #Get the Excess Heat Term \n",
    "        EH = Excess_Heat_Stress_Matrix[EH_col[2]].loc[dt]\n",
    "        \n",
    "        #Multiply together\n",
    "        \n",
    "        if ((HS <0) and (EH <0)):\n",
    "            EHF_single =  -1*EH* HS #degC^2\n",
    "        else:\n",
    "            EHF_single =  EH* HS #degC^2\n",
    "\n",
    "        #Append the date and Heat Stress Value\n",
    "        date_Values.append(Date)\n",
    "        EHF.append(EHF_single)\n",
    "        \n",
    "    #Name the terms and combine\n",
    "    EHF = pd.DataFrame(EHF,columns=['Excess Heat Factor'])\n",
    "    date_Values = pd.DataFrame(date_Values,columns=[EH_col[0]])\n",
    "    \n",
    "    EHF_vector = pd.concat([date_Values, EHF],axis=1)\n",
    "    \n",
    "    \n",
    "    return(EHF_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc2f644",
   "metadata": {},
   "source": [
    "## 6. Warm Spells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5313f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Warmwaves(Full_Dataset,binary_data):\n",
    "    \n",
    "    data = binary_data \n",
    "    #Identify warmspell of the max temperature only\n",
    "    #Outside the function we need to have\n",
    "    Data_col = Data.columns\n",
    "    #Set HW ID to 0\n",
    "    ID = 0\n",
    "    HW_Tracker = False\n",
    "    Warm_Spell_List = []\n",
    "\n",
    "    for I in range(0,len(Data)):\n",
    "        #Now lets extract the ID\n",
    "        Day = Data.loc[I]\n",
    "\n",
    "        #Are we in a heatwave condition \n",
    "        if (HW_Tracker == False):\n",
    "\n",
    "            #Check to see if EHFMx_3Sum == 3\n",
    "            if (Day[Data_col[4]] == 3):\n",
    "                #Now chekc if EHF_3Sum > 5\n",
    "\n",
    "                if(Day[Data_col[5]] >= 5):\n",
    "                    #Identify this as a heatwave event\n",
    "                    ID = ID + 1\n",
    "                    HW_Tracker = True\n",
    "                    Initital_ID = I - 2\n",
    "                    breakdays = 0\n",
    "\n",
    "                else:\n",
    "                    HW_Tracker = False\n",
    "\n",
    "            else:\n",
    "                #This means it is not a initation of a heatwave\n",
    "                HW_Tracker = False\n",
    "\n",
    "\n",
    "        else:\n",
    "            #Now this is where we check the breakdays etc\n",
    "            #If EH_Bin is positive for at least the day or night the heatwave continues\n",
    "            if (Day[Data_col[3]] > 0):\n",
    "                HW_Tracker = True\n",
    "                breakdays = 0\n",
    "\n",
    "            else:\n",
    "                #This means we continue but we just hold onto the heatwave until we know if its greater then 2\n",
    "                breakdays = breakdays + 1\n",
    "                if (breakdays > 1):\n",
    "                    #We set the heatwave\n",
    "                    Warm_Spell  = Data.loc[Initital_ID:I-2]\n",
    "                    Warm_Spell['id'] = [ID] * len(Warm_Spell)\n",
    "                    Warm_Spell_List.append(Warm_Spell)\n",
    "                    HW_Tracker = False\n",
    "                else:\n",
    "                    HW_Tracker = True\n",
    "\n",
    "\n",
    "    Warm_Spells = pd.concat(Warm_Spell_List,axis=0)\n",
    "\n",
    "\n",
    "    del Warm_Spells['EHFMx_Bin']\n",
    "    del Warm_Spells['EHF_Bin']\n",
    "    del Warm_Spells['EH_Bin']\n",
    "    del Warm_Spells['EHFMx_3Sum']\n",
    "    del Warm_Spells['EHF_3Sum']\n",
    "    \n",
    "    FIV = Full_Dataset.set_index('date')\n",
    "    WS = Warm_Spells.set_index('date')\n",
    "    \n",
    "    Warm_Waves = FIV.merge(WS, right_index=True,left_index=True)\n",
    "    del Warm_Waves['EHFMx_Bin']\n",
    "    del Warm_Waves['EHFMn_Bin']\n",
    "    del Warm_Waves['EHMx_Bin']\n",
    "    del Warm_Waves['EHMn_Bin']\n",
    "    del Warm_Waves['EH_Bin']\n",
    "    del Warm_Waves['EHF_Bin']\n",
    "    return(Warm_Waves.reset_index())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7bbc96",
   "metadata": {},
   "source": [
    "## 7. Heatwave Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1470f1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Heatwave_Function(Data):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    Data : DataFrame\n",
    "        The warm and heatwaves DataFrame\n",
    "        date / Max / Min / Excess Heat FactorMax/Heat StressMax/Excess HeatMax/Excess Heat FactorMin/Heat StressMin/Excess HeatMin/id\n",
    "        col 0 col 1 col 2  col 3                  col 4          col 5           col 6                   col 7        col 8         col 9\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    Heatwaves : DataFrames\n",
    "        The warm and heatwaves DataFrame is then reduced to Nov to Mar aka the Extended Summer Season for heatwave research.\n",
    "    '''\n",
    "    #Extract Columns\n",
    "    Data_Col = Data.columns  \n",
    "    \n",
    "    #Get dates into days months and years\n",
    "    Hot_Per = Date_Splitter(Data)\n",
    "    #it will come out with, month year and day\n",
    "    \n",
    "    #This finds the heatwaves that reside in the extended summer period defined by Novmeber to March\n",
    "    ext_sum_heatwave = Hot_Per[Hot_Per['month']>=11]\n",
    "    ext_sum_heatwave2 =  Hot_Per[Hot_Per['month']<=3]\n",
    "    \n",
    "    Extended_Summer_Season = pd.concat([ext_sum_heatwave,ext_sum_heatwave2]).sort_values(by=[Data_Col[0]], ascending=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #Generate a list of ids that will be used and checked to see if they are on the bounds of Nov and March\n",
    "    #as these are o as the bounds cut off heatwaves that begin or end of Nov and Mar respectively\n",
    "    id_Max = Extended_Summer_Season['id'] \n",
    "    ids = id_Max.drop_duplicates( keep='first', inplace=False)\n",
    "\n",
    "    \n",
    "    \n",
    "    '''The checker for the left and right bounds'''\n",
    "    for i in ids:\n",
    "        #Checks November-1\n",
    "        CheckL = Extended_Summer_Season[Extended_Summer_Season['id']==i]\n",
    "        LeftCheck = CheckL[CheckL['day']==1]\n",
    "        LeftCheck = LeftCheck[LeftCheck['month']==11]\n",
    "        #Checks March-31\n",
    "        CheckR = Extended_Summer_Season[Extended_Summer_Season['id']==i]\n",
    "        RightCheck = CheckR[CheckR['day']==31]\n",
    "        RightCheck = RightCheck[RightCheck['month']==3]\n",
    "        \n",
    "      \n",
    "        #If there is a value on the ends here it add it to the heatwave list\n",
    "        if (len(LeftCheck) == 1):\n",
    "            \n",
    "            Extended_Summer_Season = pd.concat([Extended_Summer_Season,Hot_Per[Hot_Per[Data_Col[9]]==i]]).sort_values(by=[Data_Col[0]], ascending=True)   \n",
    "    \n",
    "        elif (len(RightCheck) == 1):\n",
    "            Extended_Summer_Season = pd.concat([Extended_Summer_Season,Hot_Per[Hot_Per[Data_Col[9]]==i]]).sort_values(by=[Data_Col[0]], ascending=True)\n",
    "        \n",
    "    # removes the duplicates if there were heatwaves on any of the bounds\n",
    "    Extended_Summer_Season= Extended_Summer_Season.drop_duplicates(subset = [Data_Col[0]],keep='first')\n",
    "    #Clean up  dataset    \n",
    "    Extended_Summer_Season = Extended_Summer_Season.drop(['day','month','year'],axis=1)\n",
    "    \n",
    "    #fix the id's\n",
    "    #New id\n",
    "    Heatwaves = []\n",
    "    id_n = 0\n",
    "    for i in ids:\n",
    "        id_n = id_n+1\n",
    "        Event = Extended_Summer_Season[Extended_Summer_Season['id']==i]\n",
    "        Event['id'] = [id_n] * len(Event)\n",
    "        Heatwaves.append(Event)\n",
    "    Heatwaves = pd.concat(Heatwaves,axis=0)\n",
    "        \n",
    "    return(Heatwaves)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b0212e",
   "metadata": {},
   "source": [
    "## 8 Heatwave Table Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2810f52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Heatwave_Table_Generator(data):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    Data : DataFrame\n",
    "        The Heatwave dataframe\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    Heatwaves : DataFrames\n",
    "        An extension and clean up of the Heatwaves dataframe that provides more insight to the heatwaves.\n",
    "    \n",
    "    '''\n",
    "    # Add a new column called \"ave\" that calculates the average of the \"Max\" and \"Min\" columnsHeatwavesI\n",
    "    Heatwaves =data\n",
    "    #Get columns \n",
    "    \n",
    "    HW_Col = Heatwaves.columns\n",
    "    \n",
    "    \n",
    "    Heatwaves['Avg'] = (Heatwaves[HW_Col[1]] + Heatwaves[HW_Col[2]]) / 2\n",
    "\n",
    "    # Group the DataFrame by the \"id\" column and calculate the difference between the first and last dates of each group\n",
    "    duration = Heatwaves.groupby('id')['date'].agg([min, max]).reset_index()\n",
    "    print(duration)\n",
    "    duration['Duration'] = (pd.to_datetime(duration['max']) - pd.to_datetime(duration['min'])).dt.days + 1\n",
    "\n",
    "    # Merge the \"Duration\" column back into the original DataFrame\n",
    "    Heatwaves = pd.merge(Heatwaves, duration[['id', 'Duration']], on='id')\n",
    "\n",
    "    # Calculate the mean \"Max\", \"Min\", and \"ave\" values for each event\n",
    "    mean_values = Heatwaves.groupby('id')[[HW_Col[1], HW_Col[2], 'Avg']].mean().reset_index()\n",
    "\n",
    "    # Rename the columns to include \"Mean\" in the column names\n",
    "    mean_values = mean_values.rename(columns={HW_Col[1]: 'Max Mean', HW_Col[2]: 'Min Mean', 'Avg': 'Avg Mean'})\n",
    "\n",
    "    # Merge the \"Mean\" columns back into the original DataFrame\n",
    "    Heatwaves = pd.merge(Heatwaves, mean_values, on='id')\n",
    "\n",
    "    # Add a column for the total excess heat factor\n",
    "    Heatwaves['Total Excess Heat Factor'] = Heatwaves['Excess Heat FactorMax'] + Heatwaves['Excess Heat FactorMin']\n",
    "\n",
    "\n",
    "    # Define a function to calculate the intensity for a given heatwave event ID\n",
    "    def calculate_intensity(event_id):\n",
    "        event_data = Heatwaves[Heatwaves['id'] == event_id]\n",
    "        top_3_factors = event_data['Total Excess Heat Factor'].nlargest(3)\n",
    "        intensity = top_3_factors.mean()\n",
    "        return intensity\n",
    "\n",
    "    # Calculate the intensity for each heatwave event and add it to the Heatwaves DataFrame\n",
    "    Heatwaves['Intensity'] = Heatwaves['id'].apply(calculate_intensity)\n",
    "\n",
    "\n",
    "    # Round the columns to two decimal places\n",
    "    Heatwaves['Intensity'] = Heatwaves['Intensity'].round(2)\n",
    "    Heatwaves['Max Mean'] = Heatwaves['Max Mean'].round(2)\n",
    "    Heatwaves['Min Mean'] = Heatwaves['Min Mean'].round(2)\n",
    "    Heatwaves['Avg Mean'] = Heatwaves['Avg Mean'].round(2)\n",
    "    Heatwaves['Excess Heat FactorMax'] = Heatwaves['Excess Heat FactorMax'].round(2)\n",
    "    Heatwaves['Excess Heat FactorMin'] = Heatwaves['Excess Heat FactorMin'].round(2)\n",
    "    Heatwaves['Heat StressMax'] = Heatwaves['Heat StressMax'].round(2)\n",
    "    Heatwaves['Heat StressMin'] = Heatwaves['Heat StressMin'].round(2)\n",
    "    Heatwaves['Excess HeatMax'] = Heatwaves['Excess HeatMax'].round(2)\n",
    "    Heatwaves['Excess HeatMin'] = Heatwaves['Excess HeatMin'].round(2)\n",
    "    Heatwaves['Total Excess Heat Factor'] = Heatwaves['Total Excess Heat Factor'].round(2)\n",
    "    Heatwaves['Avg'] = Heatwaves['Avg'].round(2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    Heatwaves_Data = Heatwaves.copy()\n",
    "\n",
    "    # create a function to assign the RHC category\n",
    "    def assign_rhc_category(intensity, duration):\n",
    "        if intensity < 10 and duration <= 4:\n",
    "            return 'RHC Cat 1'\n",
    "        elif intensity < 10 and duration > 4:\n",
    "            return 'RHC Cat 2'\n",
    "        elif intensity >= 10 and intensity < 20 and duration <= 4:\n",
    "            return 'RHC Cat 2'\n",
    "        elif intensity >= 10 and intensity < 20 and duration > 4:\n",
    "            return 'RHC Cat 3'\n",
    "        elif intensity >= 20 and intensity < 30 and duration <= 4:\n",
    "            return 'RHC Cat 3'\n",
    "        elif intensity >= 20 and intensity < 30 and duration > 4:\n",
    "            return 'RHC Cat 4'\n",
    "        elif intensity >= 30 and intensity < 40 and duration <= 4:\n",
    "            return 'RHC Cat 4'\n",
    "        elif intensity >= 30 and intensity < 40 and duration > 4:\n",
    "            return 'RHC Cat 5'\n",
    "        elif intensity >= 40 and intensity <= 50 and duration <= 4:\n",
    "            return 'RHC Cat 5'\n",
    "        elif intensity >= 40 and intensity <= 50 and duration > 4:\n",
    "            return 'RHC Cat 6'\n",
    "        elif intensity > 50 and duration <= 4:\n",
    "            return 'RHC Cat 6'\n",
    "        elif intensity > 40 and intensity <= 50 and duration > 4:\n",
    "            return 'RHC Cat 6'\n",
    "        else:\n",
    "            return 'RHC Cat 7'\n",
    "\n",
    "    # add the RHC column to the dataframe\n",
    "    Heatwaves['Rowe Heatwave Categorisation'] = Heatwaves.apply(lambda x: assign_rhc_category(x['Intensity'], x['Duration']), axis=1)\n",
    "    Heatwaves['Intensity'] = Heatwaves['Intensity'].astype(str) + ' \\u00b0C' + '\\xb2'  # Concatenate the string \"degC^2\"\n",
    "    Heatwaves['Max Mean'] = Heatwaves['Max Mean'].astype(str) + ' \\u00b0C'   # Concatenate the string \"degC\"\n",
    "    Heatwaves['Min Mean'] = Heatwaves['Min Mean'].astype(str) + ' \\u00b0C'   # Concatenate the string \"degC\"\n",
    "    Heatwaves['Avg Mean'] = Heatwaves['Avg Mean'].astype(str) + ' \\u00b0C'   # Concatenate the string \"degC\"\n",
    "    Heatwaves['Excess Heat FactorMax'] = Heatwaves['Excess Heat FactorMax'].astype(str) + ' \\u00b0C' + '\\xb2'    # Concatenate the string \"degC\"\n",
    "    Heatwaves['Excess Heat FactorMin'] = Heatwaves['Excess Heat FactorMin'].astype(str) + ' \\u00b0C' + '\\xb2'    # Concatenate the string \"degC\"\n",
    "    Heatwaves['Heat StressMax'] = Heatwaves['Heat StressMax'].astype(str) + ' \\u00b0C'\n",
    "    Heatwaves['Heat StressMin'] = Heatwaves['Heat StressMin'].astype(str) + ' \\u00b0C'\n",
    "    Heatwaves['Excess HeatMax'] = Heatwaves['Excess HeatMax'].astype(str) + ' \\u00b0C'\n",
    "    Heatwaves['Excess HeatMin'] = Heatwaves['Excess HeatMin'].astype(str) + ' \\u00b0C'\n",
    "    Heatwaves['Total Excess Heat Factor'] = Heatwaves['Total Excess Heat Factor'].astype(str) + ' \\u00b0C'\n",
    "    Heatwaves[HW_Col[1]] = Heatwaves[HW_Col[1]].astype(str) + ' \\u00b0C'   # Concatenate the string \"degC\"\n",
    "    Heatwaves[HW_Col[2]] = Heatwaves[HW_Col[2]].astype(str) + ' \\u00b0C'   # Concatenate the string \"degC\"\n",
    "    Heatwaves['Avg'] = Heatwaves['Avg'].astype(str) + ' \\u00b0C'   # Concatenate the string \"degC\"\n",
    "    Heatwaves['Duration'] = Heatwaves['Duration'].astype(str) + ' days'# Concatenate the string \"degC\"\n",
    "\n",
    "    # Rearrange columns in the Heatwaves dataframe\n",
    "    Heatwaves = Heatwaves.reindex(columns=['date', 'id', 'Rowe Heatwave Categorisation',HW_Col[1], HW_Col[2], 'Avg', 'Duration', 'Intensity', 'Max Mean', 'Min Mean', 'Avg Mean', 'Excess Heat FactorMax', 'Heat StressMax', 'Excess HeatMax', 'Excess Heat FactorMin', 'Heat StressMin', 'Excess HeatMin', 'Total Excess Heat Factor'])\n",
    "    # Define a list of colors to use\n",
    "    colors = ['white', 'gray']\n",
    "\n",
    "    # Create a dictionary to map each id to a color\n",
    "    id_color_map = {}\n",
    "    for i, id in enumerate(Heatwaves['id'].unique()):\n",
    "        id_color_map[id] = colors[i % len(colors)]\n",
    "\n",
    "    # Define a function to apply the color to each row based on the id\n",
    "    def apply_color(row):\n",
    "        color = id_color_map.get(row['id'])\n",
    "        return ['background-color: {}'.format(color)] * len(row)\n",
    "\n",
    "    # Apply the color to the dataframe\n",
    "    Heatwaves = Heatwaves.style.apply(apply_color, axis=1, subset=Heatwaves.columns)\n",
    "    return(Heatwaves,Heatwaves_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f077c88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
